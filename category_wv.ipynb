{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.similarities.annoy import AnnoyIndexer\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"JEOPARDY_QUESTIONS1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>air_date</th>\n",
       "      <th>question</th>\n",
       "      <th>value</th>\n",
       "      <th>answer</th>\n",
       "      <th>round</th>\n",
       "      <th>show_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HISTORY</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'For the last 8 years of his life, Galileo was...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'No. 2: 1912 Olympian; football star at Carlis...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'The city of Yuma in this state has a record a...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'In 1963, live on \"The Art Linkletter Show\", t...</td>\n",
       "      <td>$200</td>\n",
       "      <td>McDonald\\'s</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'Signer of the Dec. of Indep., framer of the C...</td>\n",
       "      <td>$200</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216925</th>\n",
       "      <td>RIDDLE ME THIS</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>'This Puccini opera turns on the solution to 3...</td>\n",
       "      <td>$2000</td>\n",
       "      <td>Turandot</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216926</th>\n",
       "      <td>\"T\" BIRDS</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>'In North America this term is properly applie...</td>\n",
       "      <td>$2000</td>\n",
       "      <td>a titmouse</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216927</th>\n",
       "      <td>AUTHORS IN THEIR YOUTH</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>'In Penny Lane, where this \"Hellraiser\" grew u...</td>\n",
       "      <td>$2000</td>\n",
       "      <td>Clive Barker</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216928</th>\n",
       "      <td>QUOTATIONS</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>'From Ft. Sill, Okla. he made the plea, Arizon...</td>\n",
       "      <td>$2000</td>\n",
       "      <td>Geronimo</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216929</th>\n",
       "      <td>HISTORIC NAMES</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>'A silent movie title includes the last name o...</td>\n",
       "      <td>None</td>\n",
       "      <td>Grigori Alexandrovich Potemkin</td>\n",
       "      <td>Final Jeopardy!</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216930 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               category    air_date  \\\n",
       "0                               HISTORY  2004-12-31   \n",
       "1       ESPN's TOP 10 ALL-TIME ATHLETES  2004-12-31   \n",
       "2           EVERYBODY TALKS ABOUT IT...  2004-12-31   \n",
       "3                      THE COMPANY LINE  2004-12-31   \n",
       "4                   EPITAPHS & TRIBUTES  2004-12-31   \n",
       "...                                 ...         ...   \n",
       "216925                   RIDDLE ME THIS  2006-05-11   \n",
       "216926                        \"T\" BIRDS  2006-05-11   \n",
       "216927           AUTHORS IN THEIR YOUTH  2006-05-11   \n",
       "216928                       QUOTATIONS  2006-05-11   \n",
       "216929                   HISTORIC NAMES  2006-05-11   \n",
       "\n",
       "                                                 question  value  \\\n",
       "0       'For the last 8 years of his life, Galileo was...   $200   \n",
       "1       'No. 2: 1912 Olympian; football star at Carlis...   $200   \n",
       "2       'The city of Yuma in this state has a record a...   $200   \n",
       "3       'In 1963, live on \"The Art Linkletter Show\", t...   $200   \n",
       "4       'Signer of the Dec. of Indep., framer of the C...   $200   \n",
       "...                                                   ...    ...   \n",
       "216925  'This Puccini opera turns on the solution to 3...  $2000   \n",
       "216926  'In North America this term is properly applie...  $2000   \n",
       "216927  'In Penny Lane, where this \"Hellraiser\" grew u...  $2000   \n",
       "216928  'From Ft. Sill, Okla. he made the plea, Arizon...  $2000   \n",
       "216929  'A silent movie title includes the last name o...   None   \n",
       "\n",
       "                                answer             round  show_number  \n",
       "0                           Copernicus         Jeopardy!         4680  \n",
       "1                           Jim Thorpe         Jeopardy!         4680  \n",
       "2                              Arizona         Jeopardy!         4680  \n",
       "3                          McDonald\\'s         Jeopardy!         4680  \n",
       "4                           John Adams         Jeopardy!         4680  \n",
       "...                                ...               ...          ...  \n",
       "216925                        Turandot  Double Jeopardy!         4999  \n",
       "216926                      a titmouse  Double Jeopardy!         4999  \n",
       "216927                    Clive Barker  Double Jeopardy!         4999  \n",
       "216928                        Geronimo  Double Jeopardy!         4999  \n",
       "216929  Grigori Alexandrovich Potemkin   Final Jeopardy!         4999  \n",
       "\n",
       "[216930 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = set([i.lower() for i in df['category']])\n",
    "categories = list(categories)\n",
    "# categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27916"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27995"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set([i for i in df.category])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [re.sub('[^a-zA-Z]', ' ', cat) for cat in categories]\n",
    "categories = [re.sub(r'\\s+', ' ', cat) for cat in categories]\n",
    "categories = [c.strip() for c in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = [nltk.sent_tokenize(c) for c in categories] \n",
    "\n",
    "all_words = [nltk.word_tokenize(c) for cat in category for c in cat]\n",
    "\n",
    "# Removing Stop Words\n",
    "for i in range(len(all_words)):\n",
    "    all_words[i] = [w for w in all_words[i] if w not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(all_words, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x7f95303e95e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = word2vec.wv\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movie', 0.9045835137367249),\n",
       " ('tv', 0.9029242396354675),\n",
       " ('american', 0.9016271233558655),\n",
       " ('names', 0.8976449966430664),\n",
       " ('world', 0.8957473635673523),\n",
       " ('name', 0.894204318523407),\n",
       " ('old', 0.8903971314430237),\n",
       " ('u', 0.8894762396812439),\n",
       " ('national', 0.8835700154304504),\n",
       " ('film', 0.8817870020866394)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.most_similar('history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movie', 0.9339285492897034),\n",
       " ('u', 0.9282433986663818),\n",
       " ('tv', 0.9108729958534241),\n",
       " ('words', 0.910126805305481),\n",
       " ('names', 0.9076410531997681),\n",
       " ('state', 0.9053557515144348),\n",
       " ('sports', 0.9039403796195984),\n",
       " ('american', 0.8988625407218933),\n",
       " ('first', 0.8968532085418701),\n",
       " ('category', 0.8960384726524353)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.most_similar('world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate Neighbors\n",
      "('history', 0.9998273665114539)\n",
      "('american', 0.7853281199932098)\n",
      "('tv', 0.7845088094472885)\n",
      "('movie', 0.7809436619281769)\n",
      "('old', 0.7762740403413773)\n",
      "('names', 0.7698773592710495)\n",
      "('u', 0.7675094604492188)\n",
      "('world', 0.7663684487342834)\n",
      "('sports', 0.7643802464008331)\n",
      "('name', 0.7629969716072083)\n",
      "('presidential', 0.7625374346971512)\n",
      "\n",
      "Exact Neighbors\n",
      "('history', 1.0)\n",
      "('american', 0.9078319668769836)\n",
      "('tv', 0.9071270227432251)\n",
      "('movie', 0.9040284752845764)\n",
      "('old', 0.8998932838439941)\n",
      "('names', 0.8940871953964233)\n",
      "('u', 0.8918962478637695)\n",
      "('world', 0.8908324837684631)\n",
      "('sports', 0.8889665007591248)\n",
      "('name', 0.8876591324806213)\n",
      "('presidential', 0.8872230052947998)\n"
     ]
    }
   ],
   "source": [
    "annoy_index = AnnoyIndexer(word2vec, 100)\n",
    "# Derive the vector for the word \"science\" in our model\n",
    "vector = vocabulary[\"history\"]\n",
    "# The instance of AnnoyIndexer we just created is passed\n",
    "approximate_neighbors = vocabulary.most_similar([vector], topn=11, indexer=annoy_index)\n",
    "# Neatly print the approximate_neighbors and their corresponding cosine similarity values\n",
    "print(\"Approximate Neighbors\")\n",
    "for neighbor in approximate_neighbors:\n",
    "    print(neighbor)\n",
    "\n",
    "normal_neighbors = vocabulary.most_similar([vector], topn=11)\n",
    "print(\"\\nExact Neighbors\")\n",
    "for neighbor in normal_neighbors:\n",
    "    print(neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(x:str):\n",
    "    annoy_index = AnnoyIndexer(word2vec, 100)\n",
    "    vector = vocabulary[x]\n",
    "    # The instance of AnnoyIndexer we just created is passed\n",
    "    approximate_neighbors = vocabulary.most_similar([vector], topn=11, indexer=annoy_index)\n",
    "    # Neatly print the approximate_neighbors and their corresponding cosine similarity values\n",
    "    print(\"Approximate Neighbors\")\n",
    "    for neighbor in approximate_neighbors:\n",
    "        print(neighbor)\n",
    "\n",
    "    normal_neighbors = vocabulary.most_similar([vector], topn=11)\n",
    "    print(\"\\nExact Neighbors\")\n",
    "    for neighbor in normal_neighbors:\n",
    "        print(neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary('science')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jeopardy_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec, vocabulary = w2v(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate Neighbors\n",
      "('history', 0.9998273665114539)\n",
      "('american', 0.7853281199932098)\n",
      "('tv', 0.7845088094472885)\n",
      "('movie', 0.7809436619281769)\n",
      "('old', 0.7762740403413773)\n",
      "('names', 0.7698773592710495)\n",
      "('u', 0.7675094604492188)\n",
      "('world', 0.7663684487342834)\n",
      "('sports', 0.7643802464008331)\n",
      "('name', 0.7629969716072083)\n",
      "('presidential', 0.7625374346971512)\n",
      "\n",
      "Exact Neighbors\n",
      "('history', 1.0)\n",
      "('american', 0.9078319668769836)\n",
      "('tv', 0.9071270227432251)\n",
      "('movie', 0.9040284752845764)\n",
      "('old', 0.8998932838439941)\n",
      "('names', 0.8940871953964233)\n",
      "('u', 0.8918962478637695)\n",
      "('world', 0.8908324837684631)\n",
      "('sports', 0.8889665007591248)\n",
      "('name', 0.8876591324806213)\n",
      "('presidential', 0.8872230052947998)\n"
     ]
    }
   ],
   "source": [
    "summary('history', word2vec, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
